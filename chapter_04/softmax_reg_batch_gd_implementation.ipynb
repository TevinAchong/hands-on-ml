{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **12. Implement batch gradient descent with early stopping for softmax regression without using Scikit-Learn, only NumPy. Use it on a classification task such as the iris dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.data.values\n",
    "X.shape # 150 instances with 4 features each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y has 150 instances\n"
     ]
    }
   ],
   "source": [
    "y = iris.target_names[iris.target]\n",
    "print(f\"y has {y.shape[0]} instances\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.2864604 ,  2.43545215, -0.78172474,  0.8268637 ,  0.13746866,\n",
       "        1.97585545,  1.51625875, -1.47111979, -0.55192639,  0.13746866,\n",
       "       -0.09232969,  1.2864604 , -0.32212804, -0.09232969, -0.09232969,\n",
       "        1.05666205, -0.55192639, -0.78172474,  0.8268637 ,  1.05666205,\n",
       "        1.7460571 , -2.39031318, -0.78172474,  0.8268637 , -0.09232969,\n",
       "        0.59706535, -0.78172474,  0.8268637 , -0.09232969,  1.7460571 ,\n",
       "        0.367267  , -0.32212804, -1.24132144,  2.66525049, -0.09232969,\n",
       "       -0.78172474, -1.93071649, -0.09232969,  0.8268637 , -1.70091814,\n",
       "        1.97585545, -1.70091814, -0.78172474,  0.59706535,  0.367267  ,\n",
       "       -1.47111979, -0.09232969,  0.13746866, -0.55192639,  0.8268637 ,\n",
       "        1.05666205,  0.367267  , -1.24132144,  0.367267  , -0.78172474,\n",
       "       -1.01152309, -0.09232969, -1.24132144, -0.32212804, -0.09232969,\n",
       "       -1.93071649,  0.367267  ,  0.13746866,  1.05666205, -0.09232969,\n",
       "       -1.24132144,  0.8268637 ,  0.8268637 , -0.09232969,  0.59706535,\n",
       "        0.367267  , -0.32212804, -0.55192639, -0.55192639,  0.367267  ,\n",
       "        0.367267  ,  1.7460571 ,  0.13746866, -0.09232969, -0.09232969,\n",
       "       -1.01152309, -0.78172474, -0.09232969, -1.70091814, -0.32212804,\n",
       "       -1.01152309,  1.51625875, -0.09232969, -0.32212804,  0.59706535,\n",
       "        1.51625875, -1.47111979,  0.59706535, -0.09232969,  1.2864604 ,\n",
       "        0.13746866, -0.09232969,  0.13746866, -0.55192639, -0.32212804,\n",
       "       -0.55192639, -0.09232969, -1.70091814, -0.32212804, -0.55192639,\n",
       "       -0.09232969,  0.8268637 , -0.55192639, -1.24132144,  2.2056538 ,\n",
       "       -1.01152309, -0.09232969])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[:, 1] - X_train[:, 1].mean()) / X_train[:, 1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the training data\n",
    "def standard_scale(np_array, col_idxs):\n",
    "    new_arr = []\n",
    "    for col_idx in col_idxs:\n",
    "        curr_col = np_array[:, col_idx]\n",
    "        for i in range(len(curr_col)):\n",
    "            col_mean = curr_col.mean()\n",
    "            col_std = curr_col.std()\n",
    "            new_arr[i] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in train set: ['setosa' 'versicolor' 'virginica']\n",
      "Unique values in train set: ['setosa' 'versicolor' 'virginica']\n",
      "Index: 0\n",
      "Actual category: setosa\n",
      "Numeric category: 0\n",
      "**************************************************\n",
      "Index: 1\n",
      "Actual category: setosa\n",
      "Numeric category: 0\n",
      "**************************************************\n",
      "Index: 2\n",
      "Actual category: virginica\n",
      "Numeric category: 2\n",
      "**************************************************\n",
      "Index: 3\n",
      "Actual category: versicolor\n",
      "Numeric category: 1\n",
      "**************************************************\n",
      "Index: 4\n",
      "Actual category: versicolor\n",
      "Numeric category: 1\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# Checking the unique values (categories)\n",
    "print(f'Unique values in train set: {np.unique(y_train)}')\n",
    "print(f'Unique values in train set: {np.unique(y_test)}')\n",
    "\n",
    "# Replacing each value with a numeric value so that we can calculate the gradients\n",
    "y_train_num = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == 'setosa':\n",
    "        y_train_num.append(0)\n",
    "    elif y_train[i] == 'versicolor':\n",
    "        y_train_num.append(1)\n",
    "    else:\n",
    "        y_train_num.append(2)\n",
    "\n",
    "# Just testing a few\n",
    "for i in range(0, 5):\n",
    "    print(f'Index: {i}')\n",
    "    print(f'Actual category: {y_train[i]}')\n",
    "    print(f'Numeric category: {y_train_num[i]}')\n",
    "    print('*'*50)\n",
    "\n",
    "y_train_num = np.array(y_train_num).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the same operation for y_test\n",
    "# Replacing each value with a numeric value so that we can calculate the gradients\n",
    "y_test_num = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == 'setosa':\n",
    "        y_test_num.append(0)\n",
    "    elif y_test[i] == 'versicolor':\n",
    "        y_test_num.append(1)\n",
    "    else:\n",
    "        y_test_num.append(2)\n",
    "\n",
    "y_test_num = np.array(y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (112, 4)\n",
      "y_train shape: (112, 1)\n",
      "**************************************************\n",
      "X_test shape: (38, 4)\n",
      "y_test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train_num.shape}\")\n",
    "print('*'*50)\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test_num.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights: [[ 0.49671415]\n",
      " [-0.1382643 ]\n",
      " [ 0.64768854]\n",
      " [ 1.52302986]]\n",
      "\n",
      "Final theta: [[1.06959719e+164]\n",
      " [5.40457088e+163]\n",
      " [7.39489945e+163]\n",
      " [2.41457761e+163]]\n"
     ]
    }
   ],
   "source": [
    "# Implementing batch gradient descent\n",
    "learning_rate = 0.02\n",
    "num_epochs = 1000\n",
    "num_instances = X_train.shape[0]\n",
    "\n",
    "np.random.seed(42)\n",
    "# Randomly initialize weights for each feature\n",
    "theta = np.random.randn(X_train.shape[1], 1)\n",
    "print(f\"Initial Weights: {theta}\\n\")\n",
    "\n",
    "# \n",
    "for epoch in range(num_epochs):\n",
    "    gradients = 2 / num_instances * X_train.T @ (X_train @ theta - y_train_num)\n",
    "    theta = theta - learning_rate * gradients\n",
    "\n",
    "# Final theta\n",
    "print(f\"Final theta: {theta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
