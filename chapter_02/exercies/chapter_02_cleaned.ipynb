{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_housing_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the housing data from ageron github\n",
    "df_housing = load_housing_data()\n",
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing stratified train test split\n",
    "# Creating a new column called income category which we used to create stratified sets\n",
    "df_housing[\"income_category\"] = pd.cut(\n",
    "    df_housing[\"median_income\"], bins=[0, 1.5, 3.0, 4.5, 6, np.inf],\n",
    "    labels=[1, 2, 3, 4, 5]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating the test and train set that will have similar income category distributions as the overall dataset\n",
    "strat_train_set, strat_test_set = train_test_split(\n",
    "    df_housing, test_size=0.2, stratify=df_housing[\"income_category\"], \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now drop the column we created just to help us stratify\n",
    "for df in (strat_train_set, strat_test_set):\n",
    "    df.drop(\"income_category\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work using `strat_train_set` from this point onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the label column from the training set\n",
    "df_housing_strat_train = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "\n",
    "# Separating the label column in the training set\n",
    "df_housing_strat_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "The pipeline to transform our data will do the following:\n",
    "1. Missing values in numerical features will be imputed by replacing them with the median for that feature. \n",
    "2. Missing values in categorical features will be imputed by replacing them with the most frequent category for that feature.\n",
    "3. A few ratio features will be computed and added to the training set: `bedrooms_ratio`, `rooms_per_house`, `people_per_house`. These should be better correlated with the `median_house_value` for each district.\n",
    "4. A few cluster similarity features will also be added. These will likely be more useful to the mdoel than latitude and longitude.\n",
    "5. Features with a long tail will be replaced by their logarithm, as most ML models prefer features with roughly uniform or Gaussian distributions.\n",
    "6. All numerical features will be standardized, as most ML algorithms prefer when all features have roughly the same scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "#### Step 1 Above ####\n",
    "def default_numeric_pipeline():\n",
    "    return make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"), \n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "#### Step 2 Above ####\n",
    "def default_categorical_pipeline():\n",
    "    return make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\")\n",
    ")\n",
    "\n",
    "#### Step 3 Above ####\n",
    "def column_ratio(df):\n",
    "    '''\n",
    "    Parameters: df -> pandas.DataFrame with at least 2 columns\n",
    "    Returns: pandas.Series that is the result of dividing every value in column 0 of df by column 1 of df\n",
    "    '''\n",
    "    return df[:, [0]] / df[:, [1]]\n",
    "\n",
    "def ratio_name(function_transformer, feature_names_in):\n",
    "    return [\"ratio\"]\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        FunctionTransformer(column_ratio, feature_names_out=ratio_name),\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "#### Step 4 Above ####\n",
    "class ClusterSimilarity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.kmeans_ = KMeans(self.n_clusters, random_state=self.random_state)\n",
    "        self.kmeans_.fit(X, sample_weight=sample_weight)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n",
    "    \n",
    "    def get_feature_names_out(self, names=None):\n",
    "        return [f\"cluster_{i}_similarity\" for i in range(self.n_clusters)]\n",
    "\n",
    "def cluster_similarity():\n",
    "    return ClusterSimilarity(\n",
    "        n_clusters=10, gamma=1., random_state=42\n",
    "    )\n",
    "\n",
    "#### Step 5 Above ####\n",
    "def log_pipeline():\n",
    "    return make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        FunctionTransformer(np.log, feature_names_out=\"one-to-one\"),\n",
    "        StandardScaler()\n",
    "    )\n",
    "\n",
    "#### Putting it altogether to actually apply each of the pipelines above to specified columns in the dataset ####\n",
    "preprocessing = ColumnTransformer([ # for each column, specify the name of the new column, the pipeline to be applied, and the columns to apply it on\n",
    "    (\"bedrooms\", ratio_pipeline(), [\"total_bedrooms\", \"total_rooms\"]), # divides total bedrooms by total rooms and returns it in a column called bedrooms ratio\n",
    "    (\"rooms_per_house\", ratio_pipeline(), [\"total_rooms\", \"households\"]),\n",
    "    (\"people_per_house\", ratio_pipeline(), [\"population\", \"households\"]),\n",
    "    (\"log\", log_pipeline(), [\"total_bedrooms\", \"total_rooms\", \"population\",\n",
    "                             \"households\", \"median_income\"]),\n",
    "    (\"geographic\", cluster_similarity(), [\"latitude\", \"longitude\"]),\n",
    "    (\"cateogorical\", default_categorical_pipeline(), \n",
    "     make_column_selector(dtype_include=object)), # categorical pipeline on object columns\n",
    "],\n",
    "remainder=default_numeric_pipeline())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing data processed and returned as type: <class 'numpy.ndarray'>\n",
      "It has the shape: (16512, 24)\n",
      "The feature names are: ['bedrooms__ratio' 'rooms_per_house__ratio' 'people_per_house__ratio'\n",
      " 'log__total_bedrooms' 'log__total_rooms' 'log__population'\n",
      " 'log__households' 'log__median_income' 'geographic__cluster_0_similarity'\n",
      " 'geographic__cluster_1_similarity' 'geographic__cluster_2_similarity'\n",
      " 'geographic__cluster_3_similarity' 'geographic__cluster_4_similarity'\n",
      " 'geographic__cluster_5_similarity' 'geographic__cluster_6_similarity'\n",
      " 'geographic__cluster_7_similarity' 'geographic__cluster_8_similarity'\n",
      " 'geographic__cluster_9_similarity'\n",
      " 'cateogorical__ocean_proximity_<1H OCEAN'\n",
      " 'cateogorical__ocean_proximity_INLAND'\n",
      " 'cateogorical__ocean_proximity_ISLAND'\n",
      " 'cateogorical__ocean_proximity_NEAR BAY'\n",
      " 'cateogorical__ocean_proximity_NEAR OCEAN'\n",
      " 'remainder__housing_median_age']\n"
     ]
    }
   ],
   "source": [
    "df_housing_strat_train_processed = preprocessing.fit_transform(\n",
    "    df_housing_strat_train)\n",
    "print(f\"Housing data processed and returned as type: {type(df_housing_strat_train_processed)}\")\n",
    "print(f\"It has the shape: {df_housing_strat_train_processed.shape}\")\n",
    "print(f\"The feature names are: {preprocessing.get_feature_names_out()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We decided on using RandomForestRegressor\n",
    "# Now we want to use GridSearchCV to find the best hyperparameters\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"random_forest\", RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
